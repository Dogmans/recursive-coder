# Copy this to .env and fill in values

# Hugging Face token (free: https://huggingface.co/settings/tokens)
HF_TOKEN=hf_your_token_here

# Model ID â€” default uses free HF Inference API
SMOL_MODEL_ID=Qwen/Qwen2.5-Coder-32B-Instruct

# Max agent reasoning steps
SMOL_MAX_STEPS=30

# Set to true ONLY if running a local model on your GPU
# SMOL_RUN_LOCAL=false
# SMOL_QUANTIZE=true
